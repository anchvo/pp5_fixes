{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Exploratory Data Analysis Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Inspect and understand the dataset via Exploratory Data Analysis. Check Data Types, Missing Data, Variables and Correlations. Perform statistic analysis to gain insight into data.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Android_Malware.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* EDA_Report.html\n",
        "* Android_Malware_converted.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Resolve the project root\n",
        "project_root = Path.cwd()\n",
        "if project_root.name == \"jupyter_notebooks\":\n",
        "    project_root = project_root.parent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, all necessary standard libaries are imported to allow using their functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import Libraries with necessary Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Settings\n",
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Raw Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, the raw dataset is loaded to be able to access the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Dataset from Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(Path.cwd().parent / \"inputs\" / \"datasets\" / \"raw\" / \"Android_Malware.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# General Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get general overview of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The first inspection shows, that there are some columns that have an object data type. For further analysis, this needs to be converted to numeric.\n",
        "\n",
        "* The expected target variable - Label - is also an object. This needs to be converted as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Pandas Profiling Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, a pandas profiling report is created via ydata_profiling. The report serves as a general overview for the whole dataset and is saved in outputs folder for future reference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import ydata_profiling and create and save Pandas Profile Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Library\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# Create Profiling Report\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "# Save Report in Outputs Folder (create if not existing)\n",
        "os.makedirs(\"outputs/eda\", exist_ok=True)\n",
        "profile.to_file(Path.cwd().parent / \"outputs\" / \"eda\" / \"EDA_Report.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The report shows detailed information about all variables. It allows to clearly identify the target variable - the label column.\n",
        "\n",
        "* The label column has four different values: android_sms_malware, android_adware, android_scareware and benign. These describe the class / category of each sample in the dataset. \n",
        "\n",
        "* Project Goal: Create a classification model to predict the label based on the features.\n",
        "\n",
        "* The other columns are potential input features that can be used for training the model. \n",
        "\n",
        "* Further study of missing values, data types and correlation is needed to see which features are useful for a prediction model for the label target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check all columns to see naming and formatting issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clean column names to avoid hidden spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = df.columns.str.strip()\n",
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Encode target variable Label and remove after encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['Label_encoded'] = le.fit_transform(df['Label'])\n",
        "\n",
        "# Print label mapping\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"ðŸŽ¯ Label mapping (target encoding):\")\n",
        "print(label_mapping)\n",
        "\n",
        "# Drop original Label column after encoding\n",
        "df.drop(columns=['Label'], inplace=True)\n",
        "print(\"ðŸ—‘ï¸ Dropped original 'Label' column after encoding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert malformed numeric object columns to numeric & show results of conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify original object columns\n",
        "original_obj_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "converted_cols = []\n",
        "\n",
        "for col in original_obj_cols:\n",
        "    try:\n",
        "        df[col] = pd.to_numeric(df[col])\n",
        "        converted_cols.append(col)\n",
        "    except ValueError:\n",
        "        pass  # Leave it as object if conversion fails\n",
        "\n",
        "# Show conversion results\n",
        "remaining_obj_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "print(\"\\nâœ… Successfully converted to numeric:\")\n",
        "print(converted_cols)\n",
        "\n",
        "print(\"\\nâŒ Still categorical or string (object):\")\n",
        "print(remaining_obj_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check column values for suspicious looking numeric columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get only relevant columns\n",
        "suspected_numeric = ['CWE Flag Count', 'Down/Up Ratio', 'Fwd Avg Bytes/Bulk']\n",
        "\n",
        "# Preview unique values to spot issues\n",
        "for col in suspected_numeric:\n",
        "    print(f\"\\nðŸ” Unique values in '{col}':\")\n",
        "    print(df[col].unique()[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert unique values of object columns to NaN / numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_clean = ['CWE Flag Count', 'Down/Up Ratio', 'Fwd Avg Bytes/Bulk']\n",
        "\n",
        "# Convert to numeric (coerce errors to NaN)\n",
        "for col in cols_to_clean:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "print(\"\\nâœ… Finished converting suspicious numeric columns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop unhelpful metadata and index object columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_to_drop = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp', 'Unnamed: 0']\n",
        "df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(\"\\nðŸ—‘ï¸ Dropped unhelpful metadata and index columns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Final check for remaining object columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_obj_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "print(\"\\n Final object columns (categorical candidates):\")\n",
        "print(final_obj_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save converted dataframe as a copy to keep original one intact & save as csv file for easier access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make copy of dataframe for further use and easier separation\n",
        "df_converted = df.copy()\n",
        "\n",
        "# Save converted dataframe as csv file for easier later access of converted data\n",
        "os.makedirs(\"outputs/data\", exist_ok=True)\n",
        "df_converted.to_csv(Path.cwd().parent / \"outputs\" / \"data\" / \"Android_Malware_converted.csv\", index=False)\n",
        "\n",
        "print(\"âœ… Saved converted dataframe as copy of original\")\n",
        "print(\"âœ… Saved converted dataframe to outputs/data/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Converted Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, the converted dataset is loaded for further analysis. It is set to df_converted to keep code clear and understandable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load converted dataset from outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_converted = pd.read_csv(Path.cwd().parent / \"outputs\" / \"data\" / \"Android_Malware_converted.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run Spearman and Pearson's correlation with target variable Label_encoded and print top 10 correlations for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spearman Correlation\n",
        "corr_spearman = df_converted.corr(method='spearman')['Label_encoded'].sort_values(key=abs, ascending=False)[1:11]\n",
        "print(\"ðŸ“Š Top 10 Spearman correlations with Label_encoded:\")\n",
        "print(corr_spearman)\n",
        "\n",
        "# Pearson Correlation\n",
        "corr_pearson = df_converted.corr(method='pearson')['Label_encoded'].sort_values(key=abs, ascending=False)[1:11]\n",
        "print(\"ðŸ“Š Top 10 Pearson correlations with Label_encoded:\")\n",
        "print(corr_pearson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select top variables to explore further"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 5\n",
        "vars_to_explore = list(set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list()))\n",
        "print(\"ðŸ”Ž Variables to explore further based on correlation:\")\n",
        "print(vars_to_explore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Distributions by Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_numerical(df, col, target_var):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=df, x=col, hue=target_var, kde=True, element=\"step\")\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "target_var = 'Label_encoded'\n",
        "\n",
        "# Subset dataframe for EDA\n",
        "df_eda = df_converted[vars_to_explore + [target_var]]\n",
        "\n",
        "# Plot each variable\n",
        "for col in vars_to_explore:\n",
        "        plot_numerical(df_eda, col, target_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Data Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for missing values per column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing = df_converted.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing[missing > 0] if missing.any() else \"No missing values!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for Outliers using IQR Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_outliers_iqr(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
        "    return outliers.count()\n",
        "\n",
        "print(\"\\nOutliers detected per numeric column (IQR method):\")\n",
        "numeric_cols = df_converted.select_dtypes(include=['number']).columns\n",
        "outliers_count = {col: detect_outliers_iqr(df_converted[col]) for col in numeric_cols}\n",
        "for col, count in outliers_count.items():\n",
        "    print(f\"{col}: {count} outliers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Skewness for numeric features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skewness = df_converted[numeric_cols].skew()\n",
        "print(\"\\nSkewness per numeric column:\")\n",
        "print(skewness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Distribution for selected numeric features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_distributions_fast(df, cols, n_cols=3):\n",
        "    plt.figure(figsize=(15, 5 * ((len(cols) + n_cols - 1) // n_cols)))\n",
        "    for i, col in enumerate(cols, 1):\n",
        "        plt.subplot((len(cols) + n_cols - 1) // n_cols, n_cols, i)\n",
        "        sns.histplot(df[col], bins=30, kde=False)  # KDE disabled and bins limited\n",
        "        plt.title(f'Distribution of {col}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot only top 5 numeric features to save time\n",
        "plot_distributions_fast(df_converted, numeric_cols[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Class Balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nClass distribution (target variable):\")\n",
        "print(df_converted['Label_encoded'].value_counts(normalize=True))\n",
        "sns.countplot(x='Label_encoded', data=df_converted)\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The class distribution shows that the dataset is imbalanced with the Benign (3) class being underrepresented. \n",
        "\n",
        "* This is important to keep in mind and might need adjusting later to avoid affecting the model performance negatively and prevent correctly identifying the benign class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Updated Pandas Profiling Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, an updated version of the Pandas Profiling report is created to allow for comparison between reports after preparing and changing the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import ydata_profiling and create and save Pandas Profile Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Library\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# Create Profiling Report\n",
        "profile = ProfileReport(df=df_converted, minimal=True)\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "# Save Report in Outputs Folder (create if not existing)\n",
        "os.makedirs(\"outputs/eda\", exist_ok=True)\n",
        "profile.to_file(Path.cwd().parent / \"outputs\" / \"eda\" / \"EDA_Report_converted.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusion and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
